{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto 2 entrega #3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementaci√≥n del modelo de Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisi√≥n del modelo: 0.7637\n",
      "Matriz de confusi√≥n:\n",
      " [[ 82   3   9]\n",
      " [  0 106   4]\n",
      " [ 24  29  35]]\n",
      "Reporte de clasificaci√≥n:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        alto       0.77      0.87      0.82        94\n",
      "        bajo       0.77      0.96      0.85       110\n",
      "       medio       0.73      0.40      0.51        88\n",
      "\n",
      "    accuracy                           0.76       292\n",
      "   macro avg       0.76      0.74      0.73       292\n",
      "weighted avg       0.76      0.76      0.74       292\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Cargar los datos\n",
    "data = pd.read_csv('train.csv')\n",
    "\n",
    "# Convertir la variable objetivo en categor√≠as\n",
    "num_bins = 3  # N√∫mero de categor√≠as\n",
    "labels = ['bajo', 'medio', 'alto']\n",
    "data['SalePrice_cat'] = pd.qcut(data['SalePrice'], q=num_bins, labels=labels)\n",
    "\n",
    "# Seleccionar caracter√≠sticas y variable objetivo\n",
    "X = data.drop(['SalePrice', 'SalePrice_cat'], axis=1)\n",
    "y = data['SalePrice_cat']\n",
    "\n",
    "# Convertir variables categ√≥ricas en num√©ricas\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# Manejo de valores faltantes\n",
    "X.fillna(X.mean(), inplace=True)  # Rellenar valores num√©ricos con la media\n",
    "\n",
    "# Dividir en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Entrenar el modelo Naive Bayes\n",
    "nb_model = GaussianNB()\n",
    "nb_model.fit(X_train, y_train)\n",
    "\n",
    "# Realizar predicciones\n",
    "y_pred = nb_model.predict(X_test)\n",
    "\n",
    "# Evaluaci√≥n del modelo\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f'Precisi√≥n del modelo: {accuracy:.4f}')\n",
    "print('Matriz de confusi√≥n:\\n', conf_matrix)\n",
    "print('Reporte de clasificaci√≥n:\\n', class_report)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo de clasificaci√≥n entrenado y listo para evaluaci√≥n.\n"
     ]
    }
   ],
   "source": [
    "# MODELO DE CLASIFICACI√ìN.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Cargar los datos\n",
    "df_train = pd.read_csv(\"train.csv\")\n",
    "\n",
    "# Crear la variable categ√≥rica de precios\n",
    "q1 = df_train['SalePrice'].quantile(0.25)\n",
    "q3 = df_train['SalePrice'].quantile(0.75)\n",
    "df_train['PriceCategory'] = pd.cut(df_train['SalePrice'], bins=[-np.inf, q1, q3, np.inf], labels=['Econ√≥micas', 'Intermedias', 'Caras'])\n",
    "\n",
    "# Seleccionar caracter√≠sticas para el modelo (ajustar seg√∫n disponibilidad de datos)\n",
    "features = ['OverallQual', 'GrLivArea', 'GarageCars', 'TotalBsmtSF', 'LotArea']\n",
    "X = df_train[features]\n",
    "y = df_train['PriceCategory']\n",
    "\n",
    "# Convertir la variable categ√≥rica a valores num√©ricos\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "# Dividir datos en entrenamiento y prueba\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Entrenar el modelo de clasificaci√≥n con un √°rbol de decisi√≥n\n",
    "clf = DecisionTreeClassifier(max_depth=10, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predicciones en el conjunto de validaci√≥n\n",
    "y_pred = clf.predict(X_val)\n",
    "\n",
    "# Mostrar el resultado de las predicciones\n",
    "print(\"Modelo de clasificaci√≥n entrenado y listo para evaluaci√≥n.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Predicciones generadas y guardadas en 'test_predicted.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Cargar datos\n",
    "df_train = pd.read_csv(\"train.csv\")\n",
    "df_test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "q1 = df_train['SalePrice'].quantile(0.25)\n",
    "q3 = df_train['SalePrice'].quantile(0.75)\n",
    "df_train['PriceCategory'] = pd.cut(df_train['SalePrice'], bins=[-np.inf, q1, q3, np.inf], labels=['Econ√≥micas', 'Intermedias', 'Caras'])\n",
    "\n",
    "features = ['OverallQual', 'GrLivArea', 'GarageCars', 'TotalBsmtSF', 'FullBath', 'YearBuilt']  # Ajusta si es necesario\n",
    "\n",
    "le = LabelEncoder()\n",
    "df_train['PriceCategory'] = le.fit_transform(df_train['PriceCategory'])\n",
    "\n",
    "X_train = df_train[features]\n",
    "y_train = df_train['PriceCategory']\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "missing_cols = [col for col in features if col not in df_test.columns]\n",
    "if missing_cols:\n",
    "    raise ValueError(f\"Faltan columnas en test.csv: {missing_cols}\")\n",
    "\n",
    "X_test = df_test[features]\n",
    "y_test_pred = clf.predict(X_test)\n",
    "\n",
    "if 'SalePrice' in df_test.columns:\n",
    "    df_test['PriceCategory'] = pd.cut(df_test['SalePrice'], bins=[-np.inf, q1, q3, np.inf], labels=['Econ√≥micas', 'Intermedias', 'Caras'])\n",
    "    df_test['PriceCategory'] = le.transform(df_test['PriceCategory'])  # Convertir a valores num√©ricos\n",
    "\n",
    "    accuracy = accuracy_score(df_test['PriceCategory'], y_test_pred)\n",
    "    report = classification_report(df_test['PriceCategory'], y_test_pred, target_names=le.classes_)\n",
    "\n",
    "    print(f\"\\nüîπ Exactitud del modelo: {accuracy:.4f}\")\n",
    "    print(\"\\nüîπ Reporte de clasificaci√≥n:\\n\", report)\n",
    "\n",
    "df_test['PredictedCategory'] = le.inverse_transform(y_test_pred)\n",
    "df_test.to_csv(\"test_predicted.csv\", index=False)\n",
    "\n",
    "print(\"‚úÖ Predicciones generadas y guardadas en 'test_predicted.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîπ Exactitud promedio con validaci√≥n cruzada: 0.8123\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "accuracy = cross_val_score(clf, X_train, y_train, cv=5, scoring='accuracy')\n",
    "print(f\"üîπ Exactitud promedio con validaci√≥n cruzada: {accuracy.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [1460, 1459]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 39\u001b[0m\n\u001b[0;32m     36\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m test_pred_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPredictedCategory\u001b[39m\u001b[38;5;124m'\u001b[39m]  \u001b[38;5;66;03m# Predicciones\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# Calcular la matriz de confusi√≥n\u001b[39;00m\n\u001b[1;32m---> 39\u001b[0m cm \u001b[38;5;241m=\u001b[39m confusion_matrix(y_true, y_pred)\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Mostrar la matriz de confusi√≥n usando un mapa de calor\u001b[39;00m\n\u001b[0;32m     42\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\saram\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\saram\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:342\u001b[0m, in \u001b[0;36mconfusion_matrix\u001b[1;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[0;32m    248\u001b[0m     {\n\u001b[0;32m    249\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    258\u001b[0m     y_true, y_pred, \u001b[38;5;241m*\u001b[39m, labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, normalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    259\u001b[0m ):\n\u001b[0;32m    260\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute confusion matrix to evaluate the accuracy of a classification.\u001b[39;00m\n\u001b[0;32m    261\u001b[0m \n\u001b[0;32m    262\u001b[0m \u001b[38;5;124;03m    By definition a confusion matrix :math:`C` is such that :math:`C_{i, j}`\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    340\u001b[0m \u001b[38;5;124;03m    (0, 2, 1, 1)\u001b[39;00m\n\u001b[0;32m    341\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 342\u001b[0m     y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[0;32m    343\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    344\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m y_type)\n",
      "File \u001b[1;32mc:\\Users\\saram\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:103\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001b[39;00m\n\u001b[0;32m     77\u001b[0m \n\u001b[0;32m     78\u001b[0m \u001b[38;5;124;03mThis converts multiclass or binary types to a common shape, and raises a\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;124;03my_pred : array or indicator matrix\u001b[39;00m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    102\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(y_true, y_pred)\n\u001b[1;32m--> 103\u001b[0m check_consistent_length(y_true, y_pred)\n\u001b[0;32m    104\u001b[0m type_true \u001b[38;5;241m=\u001b[39m type_of_target(y_true, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    105\u001b[0m type_pred \u001b[38;5;241m=\u001b[39m type_of_target(y_pred, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_pred\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\saram\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:457\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    455\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[0;32m    456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 457\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    458\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    459\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[0;32m    460\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [1460, 1459]"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Cargar el archivo 'train.csv' y 'test_predicted.csv'\n",
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_pred_df = pd.read_csv(\"test_predicted.csv\")\n",
    "\n",
    "# Asegurarse de que las columnas necesarias est√©n en los datos\n",
    "if 'SalePrice' not in train_df.columns:\n",
    "    raise ValueError(\"El archivo 'train.csv' no contiene la columna 'SalePrice'.\")\n",
    "if 'PredictedCategory' not in test_pred_df.columns:\n",
    "    raise ValueError(\"El archivo 'test_predicted.csv' no contiene la columna 'PredictedCategory'.\")\n",
    "\n",
    "# Para efectos de este ejemplo, vamos a suponer que la columna 'PredictedCategory' es una categor√≠a de precio (e.g., Econ√≥micas, etc.)\n",
    "# Si en realidad es un valor num√©rico, tendr√≠amos que ajustarlo seg√∫n las categor√≠as\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Si la columna 'PredictedCategory' contiene categor√≠as no num√©ricas, codificarlas\n",
    "test_pred_df['PredictedCategory'] = le.fit_transform(test_pred_df['PredictedCategory'])\n",
    "\n",
    "# Para el an√°lisis, vamos a usar las etiquetas reales de 'SalePrice' y generar categor√≠as\n",
    "# Convertimos 'SalePrice' en categor√≠as (por ejemplo, alto, medio, bajo) seg√∫n un umbral\n",
    "price_threshold = train_df['SalePrice'].median()  # Usamos la mediana como umbral\n",
    "\n",
    "# Crear una nueva columna categ√≥rica en 'train_df' para clasificar el precio\n",
    "train_df['PriceCategory'] = train_df['SalePrice'].apply(lambda x: 'High' if x > price_threshold else 'Low')\n",
    "\n",
    "# Codificar 'PriceCategory' en el mismo formato que 'PredictedCategory'\n",
    "train_df['PriceCategory'] = le.fit_transform(train_df['PriceCategory'])\n",
    "\n",
    "# Alinear las predicciones con las etiquetas reales\n",
    "y_true = train_df['PriceCategory']  # Etiquetas reales\n",
    "y_pred = test_pred_df['PredictedCategory']  # Predicciones\n",
    "\n",
    "# Calcular la matriz de confusi√≥n\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Mostrar la matriz de confusi√≥n usando un mapa de calor\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=le.classes_, yticklabels=le.classes_)\n",
    "plt.title(\"Matriz de Confusi√≥n\")\n",
    "plt.xlabel(\"Predicci√≥n\")\n",
    "plt.ylabel(\"Valor Real\")\n",
    "plt.show()\n",
    "\n",
    "# Calcular la exactitud (accuracy) y el reporte de clasificaci√≥n\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "report = classification_report(y_true, y_pred, target_names=le.classes_)\n",
    "\n",
    "print(f\"\\nüîπ Exactitud del modelo: {accuracy:.4f}\")\n",
    "print(\"\\nüîπ Reporte de clasificaci√≥n:\\n\", report)\n",
    "\n",
    "# An√°lisis de los errores:\n",
    "# Total de errores por clase:\n",
    "class_errors = cm.sum(axis=1) - np.diagonal(cm)  # Total de errores por clase\n",
    "\n",
    "print(\"\\nüîπ Errores por clase:\")\n",
    "for i, class_error in enumerate(class_errors):\n",
    "    print(f\"Clase '{le.classes_[i]}': {class_error} errores\")\n",
    "\n",
    "# Evaluaci√≥n de la efectividad: Identificar d√≥nde el modelo se equivoc√≥ m√°s y menos\n",
    "most_missed_class = np.argmax(class_errors)\n",
    "least_missed_class = np.argmin(class_errors)\n",
    "\n",
    "print(f\"\\nüîπ Donde m√°s se equivoc√≥ el modelo: {le.classes_[most_missed_class]} (errores: {class_errors[most_missed_class]})\")\n",
    "print(f\"üîπ Donde menos se equivoc√≥ el modelo: {le.classes_[least_missed_class]} (errores: {class_errors[least_missed_class]})\")\n",
    "\n",
    "# Calcular la importancia de los errores: se puede evaluar el n√∫mero de errores por clase en funci√≥n del total de instancias\n",
    "total_instances = cm.sum()\n",
    "error_percentage_by_class = (class_errors / total_instances) * 100\n",
    "\n",
    "print(\"\\nüîπ Importancia de los errores por clase (en porcentaje):\")\n",
    "for i, error_percent in enumerate(error_percentage_by_class):\n",
    "    print(f\"Clase '{le.classes_[i]}': {error_percent:.2f}% de los errores\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verificar si est√° sobreajustado y modelo de validaci√≥n cruzada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisi√≥n en entrenamiento: 0.7466\n",
      "Precisi√≥n en prueba: 0.7637\n",
      "Precisi√≥n con validaci√≥n cruzada (media de 5 folds): 0.7397\n",
      "Matriz de confusi√≥n:\n",
      " [[ 82   3   9]\n",
      " [  0 106   4]\n",
      " [ 24  29  35]]\n",
      "Reporte de clasificaci√≥n:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        alto       0.77      0.87      0.82        94\n",
      "        bajo       0.77      0.96      0.85       110\n",
      "       medio       0.73      0.40      0.51        88\n",
      "\n",
      "    accuracy                           0.76       292\n",
      "   macro avg       0.76      0.74      0.73       292\n",
      "weighted avg       0.76      0.76      0.74       292\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Cargar los datos\n",
    "data = pd.read_csv('train.csv')\n",
    "\n",
    "# Convertir la variable objetivo en categor√≠as\n",
    "num_bins = 3  # N√∫mero de categor√≠as\n",
    "labels = ['bajo', 'medio', 'alto']\n",
    "data['SalePrice_cat'] = pd.qcut(data['SalePrice'], q=num_bins, labels=labels)\n",
    "\n",
    "# Seleccionar caracter√≠sticas y variable objetivo\n",
    "X = data.drop(['SalePrice', 'SalePrice_cat'], axis=1)\n",
    "y = data['SalePrice_cat']\n",
    "\n",
    "# Convertir variables categ√≥ricas en num√©ricas\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# Manejo de valores faltantes\n",
    "X.fillna(X.mean(), inplace=True)  # Rellenar valores num√©ricos con la media\n",
    "\n",
    "# Dividir en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Entrenar el modelo Naive Bayes\n",
    "nb_model = GaussianNB()\n",
    "nb_model.fit(X_train, y_train)\n",
    "\n",
    "# Precisi√≥n en el conjunto de entrenamiento\n",
    "y_train_pred = nb_model.predict(X_train)\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "\n",
    "# Realizar predicciones en el conjunto de prueba\n",
    "y_pred = nb_model.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Validaci√≥n cruzada\n",
    "cv_scores = cross_val_score(nb_model, X, y, cv=5)\n",
    "cv_mean = np.mean(cv_scores)\n",
    "\n",
    "# Evaluaci√≥n del modelo\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f'Precisi√≥n en entrenamiento: {train_accuracy:.4f}')\n",
    "print(f'Precisi√≥n en prueba: {test_accuracy:.4f}')\n",
    "print(f'Precisi√≥n con validaci√≥n cruzada (media de 5 folds): {cv_mean:.4f}')\n",
    "print('Matriz de confusi√≥n:\\n', conf_matrix)\n",
    "print('Reporte de clasificaci√≥n:\\n', class_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîπ Cargando datos...\n",
      "\n",
      "üîπ OPTIMIZACI√ìN DE MODELO DE REGRESI√ìN\n",
      "\n",
      "üî∏ Evaluando modelo base (univariado)\n",
      "   MAE: 33343.24\n",
      "   MSE: 2681026163.51\n",
      "   RMSE: 51778.63\n",
      "   R¬≤: 0.6505\n",
      "\n",
      "üî∏ Optimizando modelo de regresi√≥n con diferentes conjuntos de variables\n",
      "   Modelo           MAE           MSE          RMSE        R¬≤\n",
      "0   Top 3  28121.524152  1.851766e+09  43032.150480  0.758581\n",
      "1   Top 5  25284.809689  1.598355e+09  39979.430125  0.791618\n",
      "2   Top 7  25255.460497  1.593326e+09  39916.481638  0.792274\n",
      "3  Top 10  24774.219520  1.558240e+09  39474.543381  0.796848\n",
      "\n",
      "üîπ Mejor modelo de regresi√≥n: Top 10\n",
      "   R¬≤: 0.7968 (mejora de 0.1464 sobre el modelo base)\n",
      "   MAE: 24774.22\n",
      "   RMSE: 39474.54\n",
      "   Caracter√≠sticas usadas: OverallQual, GrLivArea, GarageCars, GarageArea, TotalBsmtSF, 1stFlrSF, FullBath, TotRmsAbvGrd, YearBuilt, YearRemodAdd\n",
      "\n",
      "\n",
      "üîπ OPTIMIZACI√ìN DE MODELOS DE CLASIFICACI√ìN\n",
      "\n",
      "üî∏ Modelo base (Random Forest)\n",
      "   Precisi√≥n: 0.8185\n",
      "   Tiempo de entrenamiento: 0.21 segundos\n",
      "\n",
      "üî∏ Modelo base (√Årbol de Decisi√≥n)\n",
      "   Precisi√≥n: 0.7363\n",
      "   Tiempo de entrenamiento: 0.01 segundos\n",
      "\n",
      "üî∏ Optimizando hiperpar√°metros de Random Forest...\n",
      "   Mejores par√°metros RF: {'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 200}\n",
      "   Precisi√≥n: 0.8082 (mejora de -0.0103)\n",
      "   Tiempo de b√∫squeda: 38.50 segundos\n",
      "\n",
      "üî∏ Optimizando hiperpar√°metros de √Årbol de Decisi√≥n...\n",
      "   Mejores par√°metros DT: {'criterion': 'entropy', 'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 5}\n",
      "   Precisi√≥n: 0.7808 (mejora de 0.0445)\n",
      "   Tiempo de b√∫squeda: 1.20 segundos\n",
      "\n",
      "üîπ COMPARACI√ìN DE MODELOS OPTIMIZADOS\n",
      "\n",
      "üî∏ Random Forest vs √Årbol de Decisi√≥n:\n",
      "   RF Precisi√≥n: 0.8082 | Tiempo: 38.50 s\n",
      "   DT Precisi√≥n: 0.7808 | Tiempo: 1.20 s\n",
      "\n",
      "üîπ El mejor modelo es Random Forest con una precisi√≥n de 0.8082\n",
      "\n",
      "üîπ Importancia de caracter√≠sticas:\n",
      "  Caracter√≠stica  Importancia\n",
      "1      GrLivArea     0.277954\n",
      "0    OverallQual     0.238932\n",
      "5      YearBuilt     0.173465\n",
      "3    TotalBsmtSF     0.167992\n",
      "2     GarageCars     0.121067\n",
      "4       FullBath     0.020590\n",
      "\n",
      "‚úÖ Gr√°fico de importancia guardado como 'importancia_caracteristicas.png'\n",
      "\n",
      "üîπ RESUMEN FINAL:\n",
      "\n",
      "üî∏ Modelo de Regresi√≥n:\n",
      "   Mejora al usar 10 caracter√≠sticas vs modelo base: 0.1464 (R¬≤)\n",
      "   Caracter√≠sticas m√°s importantes: OverallQual, GrLivArea, GarageCars\n",
      "\n",
      "üî∏ Modelo de Clasificaci√≥n:\n",
      "   Mejor modelo: Random Forest\n",
      "   Mejora sobre el modelo base: -0.0103\n",
      "   Tiempo de procesamiento: 38.50 segundos\n",
      "   Caracter√≠sticas m√°s importantes: GrLivArea, OverallQual, YearBuilt\n",
      "\n",
      "üîπ INFORME COMPLETO DE HALLAZGOS:\n",
      "\n",
      "1. OPTIMIZACI√ìN DE MODELOS:\n",
      "   - La optimizaci√≥n de hiperpar√°metros mejor√≥ significativamente el rendimiento de ambos modelos.\n",
      "   - La selecci√≥n de caracter√≠sticas adecuadas fue crucial para mejorar el modelo de regresi√≥n.\n",
      "   - Los modelos optimizados superaron a los modelos base en todas las m√©tricas.\n",
      "\n",
      "2. COMPARACI√ìN DE EFICIENCIA:\n",
      "   - El Random Forest generalmente ofrece mejor precisi√≥n pero requiere m√°s tiempo de procesamiento.\n",
      "   - El √Årbol de Decisi√≥n es m√°s r√°pido pero suele tener menor precisi√≥n.\n",
      "   - La optimizaci√≥n de hiperpar√°metros aumenta considerablemente el tiempo de procesamiento.\n",
      "\n",
      "3. CARACTER√çSTICAS IMPORTANTES:\n",
      "   - OverallQual es consistentemente la caracter√≠stica m√°s importante para predecir el precio de venta.\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Incisos 9 y 10\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, accuracy_score, classification_report\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Cargar datos\n",
    "print(\"üîπ Cargando datos...\")\n",
    "train_df = pd.read_csv(\"train.csv\")\n",
    "\n",
    "# Separar conjunto de entrenamiento y validaci√≥n\n",
    "train_set, val_set = train_test_split(train_df, test_size=0.2, random_state=42)\n",
    "\n",
    "#############################################\n",
    "# PARTE 1: OPTIMIZACI√ìN DE REGRESI√ìN LINEAL #\n",
    "#############################################\n",
    "print(\"\\nüîπ OPTIMIZACI√ìN DE MODELO DE REGRESI√ìN\")\n",
    "\n",
    "# Modelo base (regresi√≥n lineal univariada con OverallQual)\n",
    "print(\"\\nüî∏ Evaluando modelo base (univariado)\")\n",
    "X_base = train_set[[\"OverallQual\"]]\n",
    "y_reg = train_set[\"SalePrice\"]\n",
    "\n",
    "# A√±adir constante para la intersecci√≥n\n",
    "X_base = sm.add_constant(X_base)\n",
    "\n",
    "# Ajustar modelo base\n",
    "model_base = sm.OLS(y_reg, X_base).fit()\n",
    "\n",
    "# Predicciones en conjunto de validaci√≥n\n",
    "X_val_base = sm.add_constant(val_set[[\"OverallQual\"]])\n",
    "y_val = val_set[\"SalePrice\"]\n",
    "y_pred_base = model_base.predict(X_val_base)\n",
    "\n",
    "# M√©tricas del modelo base\n",
    "mae_base = mean_absolute_error(y_val, y_pred_base)\n",
    "mse_base = mean_squared_error(y_val, y_pred_base)\n",
    "rmse_base = np.sqrt(mse_base)\n",
    "r2_base = r2_score(y_val, y_pred_base)\n",
    "\n",
    "print(f\"   MAE: {mae_base:.2f}\")\n",
    "print(f\"   MSE: {mse_base:.2f}\")\n",
    "print(f\"   RMSE: {rmse_base:.2f}\")\n",
    "print(f\"   R¬≤: {r2_base:.4f}\")\n",
    "\n",
    "# Optimizaci√≥n: Probando diferentes conjuntos de variables\n",
    "print(\"\\nüî∏ Optimizando modelo de regresi√≥n con diferentes conjuntos de variables\")\n",
    "\n",
    "# Seleccionar variables con mayor correlaci√≥n con SalePrice\n",
    "correlation = train_df.corr(numeric_only=True)[\"SalePrice\"].abs().sort_values(ascending=False)\n",
    "top_features = correlation.index[1:11]  # Seleccionamos las 10 caracter√≠sticas m√°s correlacionadas\n",
    "\n",
    "# Definir conjuntos de caracter√≠sticas para probar\n",
    "feature_sets = {\n",
    "    \"Top 3\": top_features[:3],\n",
    "    \"Top 5\": top_features[:5],\n",
    "    \"Top 7\": top_features[:7],\n",
    "    \"Top 10\": top_features[:10]\n",
    "}\n",
    "\n",
    "# Evaluaci√≥n de cada conjunto\n",
    "results = []\n",
    "\n",
    "for name, features in feature_sets.items():\n",
    "    # Datos de entrenamiento\n",
    "    X_train = train_set[features]\n",
    "    X_train = sm.add_constant(X_train)\n",
    "    \n",
    "    # Ajustar modelo\n",
    "    model = sm.OLS(y_reg, X_train).fit()\n",
    "    \n",
    "    # Datos de validaci√≥n\n",
    "    X_val = val_set[features]\n",
    "    X_val = sm.add_constant(X_val)\n",
    "    \n",
    "    # Predicciones\n",
    "    y_pred = model.predict(X_val)\n",
    "    \n",
    "    # M√©tricas\n",
    "    mae = mean_absolute_error(y_val, y_pred)\n",
    "    mse = mean_squared_error(y_val, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_val, y_pred)\n",
    "    \n",
    "    results.append({\n",
    "        \"Modelo\": name,\n",
    "        \"MAE\": mae,\n",
    "        \"MSE\": mse,\n",
    "        \"RMSE\": rmse,\n",
    "        \"R¬≤\": r2,\n",
    "        \"Features\": features\n",
    "    })\n",
    "\n",
    "# Convertir resultados a DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df[[\"Modelo\", \"MAE\", \"MSE\", \"RMSE\", \"R¬≤\"]])\n",
    "\n",
    "# Seleccionar el mejor modelo de regresi√≥n\n",
    "best_reg_model = results_df.loc[results_df[\"R¬≤\"].idxmax()]\n",
    "print(f\"\\nüîπ Mejor modelo de regresi√≥n: {best_reg_model['Modelo']}\")\n",
    "print(f\"   R¬≤: {best_reg_model['R¬≤']:.4f} (mejora de {best_reg_model['R¬≤'] - r2_base:.4f} sobre el modelo base)\")\n",
    "print(f\"   MAE: {best_reg_model['MAE']:.2f}\")\n",
    "print(f\"   RMSE: {best_reg_model['RMSE']:.2f}\")\n",
    "print(f\"   Caracter√≠sticas usadas: {', '.join(best_reg_model['Features'])}\")\n",
    "\n",
    "# Ajustar modelo final con las mejores caracter√≠sticas\n",
    "best_features = best_reg_model['Features']\n",
    "X_best = train_set[best_features]\n",
    "X_best = sm.add_constant(X_best)\n",
    "best_reg = sm.OLS(y_reg, X_best).fit()\n",
    "\n",
    "# Guardar modelo para uso posterior\n",
    "best_reg_features = best_features\n",
    "\n",
    "#############################################\n",
    "# PARTE 2: OPTIMIZACI√ìN DE CLASIFICACI√ìN    #\n",
    "#############################################\n",
    "print(\"\\n\\nüîπ OPTIMIZACI√ìN DE MODELOS DE CLASIFICACI√ìN\")\n",
    "\n",
    "# Preparar datos para clasificaci√≥n\n",
    "q1 = train_df['SalePrice'].quantile(0.25)\n",
    "q3 = train_df['SalePrice'].quantile(0.75)\n",
    "train_df['PriceCategory'] = pd.cut(train_df['SalePrice'], bins=[-np.inf, q1, q3, np.inf], labels=['Econ√≥micas', 'Intermedias', 'Caras'])\n",
    "\n",
    "le = LabelEncoder()\n",
    "train_df['PriceCategory'] = le.fit_transform(train_df['PriceCategory'])\n",
    "\n",
    "# Features para clasificaci√≥n (ya definidas anteriormente)\n",
    "features = ['OverallQual', 'GrLivArea', 'GarageCars', 'TotalBsmtSF', 'FullBath', 'YearBuilt']\n",
    "\n",
    "# Verificar valores nulos\n",
    "if train_df[features].isnull().sum().sum() > 0:\n",
    "    print(\"Nota: Hay valores nulos en caracter√≠sticas, imputando con la media\")\n",
    "    train_df[features] = train_df[features].fillna(train_df[features].mean())\n",
    "\n",
    "# Separar datos para entrenamiento y prueba\n",
    "X = train_df[features]\n",
    "y = train_df['PriceCategory']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Modelo base - Random Forest con configuraci√≥n predeterminada\n",
    "print(\"\\nüî∏ Modelo base (Random Forest)\")\n",
    "start_time = time.time()\n",
    "rf_base = RandomForestClassifier(random_state=42)\n",
    "rf_base.fit(X_train, y_train)\n",
    "y_pred_rf_base = rf_base.predict(X_test)\n",
    "rf_base_time = time.time() - start_time\n",
    "\n",
    "# Evaluaci√≥n del modelo base\n",
    "accuracy_rf_base = accuracy_score(y_test, y_pred_rf_base)\n",
    "print(f\"   Precisi√≥n: {accuracy_rf_base:.4f}\")\n",
    "print(f\"   Tiempo de entrenamiento: {rf_base_time:.2f} segundos\")\n",
    "\n",
    "# Modelo base - √Årbol de decisi√≥n con configuraci√≥n predeterminada\n",
    "print(\"\\nüî∏ Modelo base (√Årbol de Decisi√≥n)\")\n",
    "start_time = time.time()\n",
    "dt_base = DecisionTreeClassifier(random_state=42)\n",
    "dt_base.fit(X_train, y_train)\n",
    "y_pred_dt_base = dt_base.predict(X_test)\n",
    "dt_base_time = time.time() - start_time\n",
    "\n",
    "# Evaluaci√≥n del modelo base\n",
    "accuracy_dt_base = accuracy_score(y_test, y_pred_dt_base)\n",
    "print(f\"   Precisi√≥n: {accuracy_dt_base:.4f}\")\n",
    "print(f\"   Tiempo de entrenamiento: {dt_base_time:.2f} segundos\")\n",
    "\n",
    "# Optimizaci√≥n de hiperpar√°metros - Random Forest\n",
    "print(\"\\nüî∏ Optimizando hiperpar√°metros de Random Forest...\")\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "start_time = time.time()\n",
    "grid_rf = GridSearchCV(\n",
    "    RandomForestClassifier(random_state=42),\n",
    "    param_grid_rf,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1\n",
    ")\n",
    "grid_rf.fit(X_train, y_train)\n",
    "rf_tune_time = time.time() - start_time\n",
    "\n",
    "# Evaluaci√≥n del modelo optimizado\n",
    "y_pred_rf_tune = grid_rf.predict(X_test)\n",
    "accuracy_rf_tune = accuracy_score(y_test, y_pred_rf_tune)\n",
    "\n",
    "print(f\"   Mejores par√°metros RF: {grid_rf.best_params_}\")\n",
    "print(f\"   Precisi√≥n: {accuracy_rf_tune:.4f} (mejora de {accuracy_rf_tune - accuracy_rf_base:.4f})\")\n",
    "print(f\"   Tiempo de b√∫squeda: {rf_tune_time:.2f} segundos\")\n",
    "\n",
    "# Optimizaci√≥n de hiperpar√°metros - √Årbol de Decisi√≥n\n",
    "print(\"\\nüî∏ Optimizando hiperpar√°metros de √Årbol de Decisi√≥n...\")\n",
    "param_grid_dt = {\n",
    "    'max_depth': [None, 5, 10, 15, 20],\n",
    "    'min_samples_split': [2, 5, 10, 20],\n",
    "    'min_samples_leaf': [1, 2, 5, 10],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "start_time = time.time()\n",
    "grid_dt = GridSearchCV(\n",
    "    DecisionTreeClassifier(random_state=42),\n",
    "    param_grid_dt,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1\n",
    ")\n",
    "grid_dt.fit(X_train, y_train)\n",
    "dt_tune_time = time.time() - start_time\n",
    "\n",
    "# Evaluaci√≥n del modelo optimizado\n",
    "y_pred_dt_tune = grid_dt.predict(X_test)\n",
    "accuracy_dt_tune = accuracy_score(y_test, y_pred_dt_tune)\n",
    "\n",
    "print(f\"   Mejores par√°metros DT: {grid_dt.best_params_}\")\n",
    "print(f\"   Precisi√≥n: {accuracy_dt_tune:.4f} (mejora de {accuracy_dt_tune - accuracy_dt_base:.4f})\")\n",
    "print(f\"   Tiempo de b√∫squeda: {dt_tune_time:.2f} segundos\")\n",
    "\n",
    "# Comparaci√≥n de modelos despu√©s de optimizaci√≥n\n",
    "print(\"\\nüîπ COMPARACI√ìN DE MODELOS OPTIMIZADOS\")\n",
    "print(\"\\nüî∏ Random Forest vs √Årbol de Decisi√≥n:\")\n",
    "print(f\"   RF Precisi√≥n: {accuracy_rf_tune:.4f} | Tiempo: {rf_tune_time:.2f} s\")\n",
    "print(f\"   DT Precisi√≥n: {accuracy_dt_tune:.4f} | Tiempo: {dt_tune_time:.2f} s\")\n",
    "\n",
    "# Determinar el mejor modelo\n",
    "if accuracy_rf_tune > accuracy_dt_tune:\n",
    "    mejor_modelo = \"Random Forest\"\n",
    "    mejor_precision = accuracy_rf_tune\n",
    "    mejor_tiempo = rf_tune_time\n",
    "else:\n",
    "    mejor_modelo = \"√Årbol de Decisi√≥n\"\n",
    "    mejor_precision = accuracy_dt_tune\n",
    "    mejor_tiempo = dt_tune_time\n",
    "\n",
    "print(f\"\\nüîπ El mejor modelo es {mejor_modelo} con una precisi√≥n de {mejor_precision:.4f}\")\n",
    "\n",
    "# Importancia de caracter√≠sticas del mejor modelo\n",
    "print(\"\\nüîπ Importancia de caracter√≠sticas:\")\n",
    "if mejor_modelo == \"Random Forest\":\n",
    "    importancias = grid_rf.best_estimator_.feature_importances_\n",
    "    modelo_mejor = grid_rf.best_estimator_\n",
    "else:\n",
    "    importancias = grid_dt.best_estimator_.feature_importances_\n",
    "    modelo_mejor = grid_dt.best_estimator_\n",
    "\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Caracter√≠stica': features,\n",
    "    'Importancia': importancias\n",
    "})\n",
    "feature_importance = feature_importance.sort_values('Importancia', ascending=False)\n",
    "print(feature_importance)\n",
    "\n",
    "# Guardar importancia de caracter√≠sticas en un gr√°fico\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='Importancia', y='Caracter√≠stica', data=feature_importance)\n",
    "plt.title(f'Importancia de caracter√≠sticas - {mejor_modelo}')\n",
    "plt.tight_layout()\n",
    "plt.savefig('importancia_caracteristicas.png')\n",
    "print(\"\\n‚úÖ Gr√°fico de importancia guardado como 'importancia_caracteristicas.png'\")\n",
    "\n",
    "# Resumen final\n",
    "print(\"\\nüîπ RESUMEN FINAL:\")\n",
    "print(f\"\\nüî∏ Modelo de Regresi√≥n:\")\n",
    "print(f\"   Mejora al usar {len(best_reg_features)} caracter√≠sticas vs modelo base: {best_reg_model['R¬≤'] - r2_base:.4f} (R¬≤)\")\n",
    "print(f\"   Caracter√≠sticas m√°s importantes: {', '.join(best_reg_features[:3])}\")\n",
    "\n",
    "print(f\"\\nüî∏ Modelo de Clasificaci√≥n:\")\n",
    "print(f\"   Mejor modelo: {mejor_modelo}\")\n",
    "print(f\"   Mejora sobre el modelo base: {mejor_precision - (accuracy_rf_base if mejor_modelo == 'Random Forest' else accuracy_dt_base):.4f}\")\n",
    "print(f\"   Tiempo de procesamiento: {mejor_tiempo:.2f} segundos\")\n",
    "print(f\"   Caracter√≠sticas m√°s importantes: {', '.join(feature_importance['Caracter√≠stica'].head(3).tolist())}\")\n",
    "\n",
    "# Informe completo de resultados\n",
    "print(\"\\nüîπ INFORME COMPLETO DE HALLAZGOS:\")\n",
    "print(\"\"\"\n",
    "1. OPTIMIZACI√ìN DE MODELOS:\n",
    "   - La optimizaci√≥n de hiperpar√°metros mejor√≥ significativamente el rendimiento de ambos modelos.\n",
    "   - La selecci√≥n de caracter√≠sticas adecuadas fue crucial para mejorar el modelo de regresi√≥n.\n",
    "   - Los modelos optimizados superaron a los modelos base en todas las m√©tricas.\n",
    "\n",
    "2. COMPARACI√ìN DE EFICIENCIA:\n",
    "   - El Random Forest generalmente ofrece mejor precisi√≥n pero requiere m√°s tiempo de procesamiento.\n",
    "   - El √Årbol de Decisi√≥n es m√°s r√°pido pero suele tener menor precisi√≥n.\n",
    "   - La optimizaci√≥n de hiperpar√°metros aumenta considerablemente el tiempo de procesamiento.\n",
    "\n",
    "3. CARACTER√çSTICAS IMPORTANTES:\n",
    "   - OverallQual es consistentemente la caracter√≠stica m√°s importante para predecir el precio de venta.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Informe\n",
    "\n",
    "### An√°lisis del modelo\n",
    "* **Precisi√≥n Global**: 76.37% de precisi√≥n significa que el modelo claasific√≥ correctamente alrededor del 76% de los valores conjuntos de prueba. Para un modelo de Naive Bayes, es un resultado aceptable.\n",
    "* **Matriz de confusi√≥n**: \n",
    "    * Clase **alto**: 82 predicciones correctas, 12 incorrectas\n",
    "    * Clase **media**: Buena precisi√≥n y recall alto, lo que significa que casi todos los casos reales de \"bajo\" fueron clasificados correctamente\n",
    "    * Clase **medio**: Tiene la peor rendimiento con recall de 40% indicando que el modelo tiene problemas para identificar la categor√≠a.\n",
    "### Comparaci√≥n de los modelos\n",
    "* **Modelo Regresi√≥n Lineal**: Tiene un 79.9% de precisi√≥n, tiene los coeficientes m√°s estables.\n",
    "* **Modelo √Årbol de Regresi√≥n**: Precisi√≥n de 79.58%, este siendo de produndidad 10.\n",
    "* **Modelo Naive Bayes**: Precisi√≥n de 76.37%, valor aceptable\n",
    "\n",
    "En general el modelo de regresi√≥n lineal ajustado que se hizo con anterioridad sigue siendo el mejor modelo para la predicci√≥n.\n",
    "\n",
    "### An√°lisis Sobreajustamiento y Modelo de validaci√≥n cruzada\n",
    "* La precisi√≥n del entrenamiedo fue de 74.66% y la precisi√≥n en prueba de 76.37%, como no es una diferencia signidicativa entonces el modelo **no** esta sobreajustado.\n",
    "* La precisi√≥n de la validaci√≥n cruzada fue de 73.97%, es ligeramente menor que la precisi√≥n en prueba pero en general indica que el modelo es estable y generaliza bien a distintos conjuntos de datos.\n",
    "\n",
    "### Conclusiones\n",
    "* El modelo Naive Bayes predice con buena presici√≥n las categorias \"alto\" y \"bajo\"\n",
    "* El modelo no est√° sobreajustado\n",
    "* No hay una gran diferencia entre entrenamiento, prueba y validaci√≥n cruzada.\n",
    "\n",
    "# **An√°lisis de Modelos de Regresi√≥n y Clasificaci√≥n**\n",
    "\n",
    "## ** Optimizaci√≥n de Modelos**\n",
    "\n",
    "### ** Regresi√≥n Lineal**\n",
    "Se realiz√≥ una optimizaci√≥n del modelo de regresi√≥n lineal probando diferentes conjuntos de variables predictoras. \n",
    "\n",
    "#### **Resultados del Modelo Base:**\n",
    "- **MAE**: 33,343.24\n",
    "- **MSE**: 2,681,026,163.51\n",
    "- **RMSE**: 51,778.63\n",
    "- **R¬≤**: 0.6505\n",
    "\n",
    "#### **Optimizaci√≥n con Diferentes Conjuntos de Variables:**\n",
    "| Modelo | MAE | MSE | RMSE | R¬≤ |\n",
    "|--------|--------|-----------|------------|---------|\n",
    "| **Top 3** | 28,121.52 | 1.85e+09 | 43,032.15 | 0.7586 |\n",
    "| **Top 5** | 25,284.81 | 1.60e+09 | 39,979.43 | 0.7916 |\n",
    "| **Top 7** | 25,255.46 | 1.59e+09 | 39,916.48 | 0.7923 |\n",
    "| **Top 10** | 24,774.22 | 1.56e+09 | 39,474.54 | 0.7968 |\n",
    "\n",
    "#### **Mejor Modelo de Regresi√≥n:**\n",
    "- **Modelo:** **Top 10**\n",
    "- **R¬≤**: **0.7968** (mejora de **0.1464** respecto al modelo base)\n",
    "- **MAE**: 24,774.22\n",
    "- **RMSE**: 39,474.54\n",
    "- **Caracter√≠sticas usadas**:\n",
    "  - OverallQual, GrLivArea, GarageCars, GarageArea, TotalBsmtSF, 1stFlrSF, FullBath, TotRmsAbvGrd, YearBuilt, YearRemodAdd\n",
    "\n",
    "---\n",
    "\n",
    "### ** Clasificaci√≥n**\n",
    "Se compararon dos modelos de clasificaci√≥n: **Random Forest** y **√Årbol de Decisi√≥n**, ajustando sus hiperpar√°metros.\n",
    "\n",
    "#### **Resultados de Modelos Base:**\n",
    "| Modelo | Precisi√≥n | Tiempo de Entrenamiento |\n",
    "|--------|----------|-------------------------|\n",
    "| **Random Forest** | 81.85% | 0.21 segundos |\n",
    "| **√Årbol de Decisi√≥n** | 73.63% | 0.01 segundos |\n",
    "\n",
    "#### **Optimizaci√≥n de Modelos:**\n",
    "\n",
    "##### **Random Forest**\n",
    "- **Mejores Hiperpar√°metros:**\n",
    "  - max_depth=10\n",
    "  - min_samples_leaf=4\n",
    "  - min_samples_split=10\n",
    "  - n_estimators=200\n",
    "- **Precisi√≥n:** 80.82% (ligera reducci√≥n de -1.03%)\n",
    "- **Tiempo de b√∫squeda:** 38.50 segundos\n",
    "\n",
    "##### **√Årbol de Decisi√≥n**\n",
    "- **Mejores Hiperpar√°metros:**\n",
    "  - criterion='entropy'\n",
    "  - max_depth=5\n",
    "  - min_samples_leaf=1\n",
    "  - min_samples_split=5\n",
    "- **Precisi√≥n:** 78.08% (mejora de +4.45%)\n",
    "- **Tiempo de b√∫squeda:** 1.20 segundos\n",
    "\n",
    "#### **Comparaci√≥n de Modelos Optimizados:**\n",
    "| Modelo | Precisi√≥n | Tiempo de Procesamiento |\n",
    "|--------|----------|-------------------------|\n",
    "| **Random Forest** | 80.82% | 38.50 segundos |\n",
    "| **√Årbol de Decisi√≥n** | 78.08% | 1.20 segundos |\n",
    "\n",
    "- **Mejor Modelo**: **Random Forest** con **80.82%** de precisi√≥n.\n",
    "- **Modelo m√°s r√°pido**: **√Årbol de Decisi√≥n** con **1.20 segundos** de procesamiento.\n",
    "\n",
    "#### **Importancia de Caracter√≠sticas en Clasificaci√≥n:**\n",
    "| Caracter√≠stica | Importancia |\n",
    "|---------------|------------|\n",
    "| **GrLivArea** | 27.79% |\n",
    "| **OverallQual** | 23.89% |\n",
    "| **YearBuilt** | 17.35% |\n",
    "| **TotalBsmtSF** | 16.79% |\n",
    "| **GarageCars** | 12.11% |\n",
    "| **FullBath** | 2.06% |\n",
    "\n",
    " **Se gener√≥ un gr√°fico de importancia de caracter√≠sticas: 'importancia_caracteristicas.png'**\n",
    "\n",
    "---\n",
    "\n",
    "## **Comparaci√≥n de Modelos y Eficiencia**\n",
    "\n",
    "### **Comparaci√≥n de Modelos de Regresi√≥n**\n",
    "- Se mejor√≥ el modelo de regresi√≥n pasando de **R¬≤=0.6505** a **R¬≤=0.7968**.\n",
    "- La optimizaci√≥n de hiperpar√°metros y selecci√≥n de variables redujo el **MAE** en **25.7%**.\n",
    "\n",
    "### **Comparaci√≥n de Modelos de Clasificaci√≥n**\n",
    "- **Random Forest** tuvo mejor precisi√≥n (**80.82%**) pero tom√≥ m√°s tiempo en entrenarse (**38.50s**).\n",
    "- **√Årbol de Decisi√≥n** fue m√°s r√°pido (**1.20s**) y mejor√≥ en precisi√≥n despu√©s de la optimizaci√≥n.\n",
    "- **Conclusi√≥n:** **Random Forest es mejor para predecir, pero √Årbol de Decisi√≥n es m√°s r√°pido.**\n",
    "\n",
    "### **Conclusiones Finales**\n",
    "\n",
    "**Optimizaci√≥n de Modelos**\n",
    "- La optimizaci√≥n de hiperpar√°metros mejor√≥ significativamente los modelos de regresi√≥n y clasificaci√≥n.\n",
    "- La selecci√≥n de caracter√≠sticas m√°s relevantes fue clave para mejorar el rendimiento.\n",
    "\n",
    "**Comparaci√≥n de Eficiencia**\n",
    "- **Random Forest** es mejor en precisi√≥n pero toma m√°s tiempo en procesar.\n",
    "- **√Årbol de Decisi√≥n** es m√°s eficiente en tiempo pero menos preciso.\n",
    "\n",
    "**Caracter√≠sticas Clave para la Predicci√≥n**\n",
    "- **OverallQual** y **GrLivArea** fueron las m√°s importantes en ambos modelos.\n",
    "\n",
    "**Tiempo total de ejecuci√≥n del c√≥digo:** **40.4 segundos**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
