{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto 2 entrega #3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementaci√≥n del modelo de Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisi√≥n del modelo: 0.7637\n",
      "Matriz de confusi√≥n:\n",
      " [[ 82   3   9]\n",
      " [  0 106   4]\n",
      " [ 24  29  35]]\n",
      "Reporte de clasificaci√≥n:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        alto       0.77      0.87      0.82        94\n",
      "        bajo       0.77      0.96      0.85       110\n",
      "       medio       0.73      0.40      0.51        88\n",
      "\n",
      "    accuracy                           0.76       292\n",
      "   macro avg       0.76      0.74      0.73       292\n",
      "weighted avg       0.76      0.76      0.74       292\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Cargar los datos\n",
    "data = pd.read_csv('train.csv')\n",
    "\n",
    "# Convertir la variable objetivo en categor√≠as\n",
    "num_bins = 3  # N√∫mero de categor√≠as\n",
    "labels = ['bajo', 'medio', 'alto']\n",
    "data['SalePrice_cat'] = pd.qcut(data['SalePrice'], q=num_bins, labels=labels)\n",
    "\n",
    "# Seleccionar caracter√≠sticas y variable objetivo\n",
    "X = data.drop(['SalePrice', 'SalePrice_cat'], axis=1)\n",
    "y = data['SalePrice_cat']\n",
    "\n",
    "# Convertir variables categ√≥ricas en num√©ricas\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# Manejo de valores faltantes\n",
    "X.fillna(X.mean(), inplace=True)  # Rellenar valores num√©ricos con la media\n",
    "\n",
    "# Dividir en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Entrenar el modelo Naive Bayes\n",
    "nb_model = GaussianNB()\n",
    "nb_model.fit(X_train, y_train)\n",
    "\n",
    "# Realizar predicciones\n",
    "y_pred = nb_model.predict(X_test)\n",
    "\n",
    "# Evaluaci√≥n del modelo\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f'Precisi√≥n del modelo: {accuracy:.4f}')\n",
    "print('Matriz de confusi√≥n:\\n', conf_matrix)\n",
    "print('Reporte de clasificaci√≥n:\\n', class_report)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo de clasificaci√≥n entrenado y listo para evaluaci√≥n.\n"
     ]
    }
   ],
   "source": [
    "# MODELO DE CLASIFICACI√ìN.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Cargar los datos\n",
    "df_train = pd.read_csv(\"train.csv\")\n",
    "\n",
    "# Crear la variable categ√≥rica de precios\n",
    "q1 = df_train['SalePrice'].quantile(0.25)\n",
    "q3 = df_train['SalePrice'].quantile(0.75)\n",
    "df_train['PriceCategory'] = pd.cut(df_train['SalePrice'], bins=[-np.inf, q1, q3, np.inf], labels=['Econ√≥micas', 'Intermedias', 'Caras'])\n",
    "\n",
    "# Seleccionar caracter√≠sticas para el modelo (ajustar seg√∫n disponibilidad de datos)\n",
    "features = ['OverallQual', 'GrLivArea', 'GarageCars', 'TotalBsmtSF', 'LotArea']\n",
    "X = df_train[features]\n",
    "y = df_train['PriceCategory']\n",
    "\n",
    "# Convertir la variable categ√≥rica a valores num√©ricos\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "# Dividir datos en entrenamiento y prueba\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Entrenar el modelo de clasificaci√≥n con un √°rbol de decisi√≥n\n",
    "clf = DecisionTreeClassifier(max_depth=10, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predicciones en el conjunto de validaci√≥n\n",
    "y_pred = clf.predict(X_val)\n",
    "\n",
    "# Mostrar el resultado de las predicciones\n",
    "print(\"Modelo de clasificaci√≥n entrenado y listo para evaluaci√≥n.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Predicciones generadas y guardadas en 'test_predicted.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Cargar datos\n",
    "df_train = pd.read_csv(\"train.csv\")\n",
    "df_test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "q1 = df_train['SalePrice'].quantile(0.25)\n",
    "q3 = df_train['SalePrice'].quantile(0.75)\n",
    "df_train['PriceCategory'] = pd.cut(df_train['SalePrice'], bins=[-np.inf, q1, q3, np.inf], labels=['Econ√≥micas', 'Intermedias', 'Caras'])\n",
    "\n",
    "features = ['OverallQual', 'GrLivArea', 'GarageCars', 'TotalBsmtSF', 'FullBath', 'YearBuilt']  # Ajusta si es necesario\n",
    "\n",
    "le = LabelEncoder()\n",
    "df_train['PriceCategory'] = le.fit_transform(df_train['PriceCategory'])\n",
    "\n",
    "X_train = df_train[features]\n",
    "y_train = df_train['PriceCategory']\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "missing_cols = [col for col in features if col not in df_test.columns]\n",
    "if missing_cols:\n",
    "    raise ValueError(f\"Faltan columnas en test.csv: {missing_cols}\")\n",
    "\n",
    "X_test = df_test[features]\n",
    "y_test_pred = clf.predict(X_test)\n",
    "\n",
    "if 'SalePrice' in df_test.columns:\n",
    "    df_test['PriceCategory'] = pd.cut(df_test['SalePrice'], bins=[-np.inf, q1, q3, np.inf], labels=['Econ√≥micas', 'Intermedias', 'Caras'])\n",
    "    df_test['PriceCategory'] = le.transform(df_test['PriceCategory'])  # Convertir a valores num√©ricos\n",
    "\n",
    "    accuracy = accuracy_score(df_test['PriceCategory'], y_test_pred)\n",
    "    report = classification_report(df_test['PriceCategory'], y_test_pred, target_names=le.classes_)\n",
    "\n",
    "    print(f\"\\nüîπ Exactitud del modelo: {accuracy:.4f}\")\n",
    "    print(\"\\nüîπ Reporte de clasificaci√≥n:\\n\", report)\n",
    "\n",
    "df_test['PredictedCategory'] = le.inverse_transform(y_test_pred)\n",
    "df_test.to_csv(\"test_predicted.csv\", index=False)\n",
    "\n",
    "print(\"‚úÖ Predicciones generadas y guardadas en 'test_predicted.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîπ Exactitud promedio con validaci√≥n cruzada: 0.8123\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "accuracy = cross_val_score(clf, X_train, y_train, cv=5, scoring='accuracy')\n",
    "print(f\"üîπ Exactitud promedio con validaci√≥n cruzada: {accuracy.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [1460, 1459]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 39\u001b[0m\n\u001b[0;32m     36\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m test_pred_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPredictedCategory\u001b[39m\u001b[38;5;124m'\u001b[39m]  \u001b[38;5;66;03m# Predicciones\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# Calcular la matriz de confusi√≥n\u001b[39;00m\n\u001b[1;32m---> 39\u001b[0m cm \u001b[38;5;241m=\u001b[39m confusion_matrix(y_true, y_pred)\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Mostrar la matriz de confusi√≥n usando un mapa de calor\u001b[39;00m\n\u001b[0;32m     42\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\saram\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\saram\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:342\u001b[0m, in \u001b[0;36mconfusion_matrix\u001b[1;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[0;32m    248\u001b[0m     {\n\u001b[0;32m    249\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    258\u001b[0m     y_true, y_pred, \u001b[38;5;241m*\u001b[39m, labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, normalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    259\u001b[0m ):\n\u001b[0;32m    260\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute confusion matrix to evaluate the accuracy of a classification.\u001b[39;00m\n\u001b[0;32m    261\u001b[0m \n\u001b[0;32m    262\u001b[0m \u001b[38;5;124;03m    By definition a confusion matrix :math:`C` is such that :math:`C_{i, j}`\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    340\u001b[0m \u001b[38;5;124;03m    (0, 2, 1, 1)\u001b[39;00m\n\u001b[0;32m    341\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 342\u001b[0m     y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[0;32m    343\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    344\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m y_type)\n",
      "File \u001b[1;32mc:\\Users\\saram\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:103\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001b[39;00m\n\u001b[0;32m     77\u001b[0m \n\u001b[0;32m     78\u001b[0m \u001b[38;5;124;03mThis converts multiclass or binary types to a common shape, and raises a\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;124;03my_pred : array or indicator matrix\u001b[39;00m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    102\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(y_true, y_pred)\n\u001b[1;32m--> 103\u001b[0m check_consistent_length(y_true, y_pred)\n\u001b[0;32m    104\u001b[0m type_true \u001b[38;5;241m=\u001b[39m type_of_target(y_true, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    105\u001b[0m type_pred \u001b[38;5;241m=\u001b[39m type_of_target(y_pred, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_pred\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\saram\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:457\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    455\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[0;32m    456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 457\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    458\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    459\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[0;32m    460\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [1460, 1459]"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Cargar el archivo 'train.csv' y 'test_predicted.csv'\n",
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_pred_df = pd.read_csv(\"test_predicted.csv\")\n",
    "\n",
    "# Asegurarse de que las columnas necesarias est√©n en los datos\n",
    "if 'SalePrice' not in train_df.columns:\n",
    "    raise ValueError(\"El archivo 'train.csv' no contiene la columna 'SalePrice'.\")\n",
    "if 'PredictedCategory' not in test_pred_df.columns:\n",
    "    raise ValueError(\"El archivo 'test_predicted.csv' no contiene la columna 'PredictedCategory'.\")\n",
    "\n",
    "# Para efectos de este ejemplo, vamos a suponer que la columna 'PredictedCategory' es una categor√≠a de precio (e.g., Econ√≥micas, etc.)\n",
    "# Si en realidad es un valor num√©rico, tendr√≠amos que ajustarlo seg√∫n las categor√≠as\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Si la columna 'PredictedCategory' contiene categor√≠as no num√©ricas, codificarlas\n",
    "test_pred_df['PredictedCategory'] = le.fit_transform(test_pred_df['PredictedCategory'])\n",
    "\n",
    "# Para el an√°lisis, vamos a usar las etiquetas reales de 'SalePrice' y generar categor√≠as\n",
    "# Convertimos 'SalePrice' en categor√≠as (por ejemplo, alto, medio, bajo) seg√∫n un umbral\n",
    "price_threshold = train_df['SalePrice'].median()  # Usamos la mediana como umbral\n",
    "\n",
    "# Crear una nueva columna categ√≥rica en 'train_df' para clasificar el precio\n",
    "train_df['PriceCategory'] = train_df['SalePrice'].apply(lambda x: 'High' if x > price_threshold else 'Low')\n",
    "\n",
    "# Codificar 'PriceCategory' en el mismo formato que 'PredictedCategory'\n",
    "train_df['PriceCategory'] = le.fit_transform(train_df['PriceCategory'])\n",
    "\n",
    "# Alinear las predicciones con las etiquetas reales\n",
    "y_true = train_df['PriceCategory']  # Etiquetas reales\n",
    "y_pred = test_pred_df['PredictedCategory']  # Predicciones\n",
    "\n",
    "# Calcular la matriz de confusi√≥n\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Mostrar la matriz de confusi√≥n usando un mapa de calor\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=le.classes_, yticklabels=le.classes_)\n",
    "plt.title(\"Matriz de Confusi√≥n\")\n",
    "plt.xlabel(\"Predicci√≥n\")\n",
    "plt.ylabel(\"Valor Real\")\n",
    "plt.show()\n",
    "\n",
    "# Calcular la exactitud (accuracy) y el reporte de clasificaci√≥n\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "report = classification_report(y_true, y_pred, target_names=le.classes_)\n",
    "\n",
    "print(f\"\\nüîπ Exactitud del modelo: {accuracy:.4f}\")\n",
    "print(\"\\nüîπ Reporte de clasificaci√≥n:\\n\", report)\n",
    "\n",
    "# An√°lisis de los errores:\n",
    "# Total de errores por clase:\n",
    "class_errors = cm.sum(axis=1) - np.diagonal(cm)  # Total de errores por clase\n",
    "\n",
    "print(\"\\nüîπ Errores por clase:\")\n",
    "for i, class_error in enumerate(class_errors):\n",
    "    print(f\"Clase '{le.classes_[i]}': {class_error} errores\")\n",
    "\n",
    "# Evaluaci√≥n de la efectividad: Identificar d√≥nde el modelo se equivoc√≥ m√°s y menos\n",
    "most_missed_class = np.argmax(class_errors)\n",
    "least_missed_class = np.argmin(class_errors)\n",
    "\n",
    "print(f\"\\nüîπ Donde m√°s se equivoc√≥ el modelo: {le.classes_[most_missed_class]} (errores: {class_errors[most_missed_class]})\")\n",
    "print(f\"üîπ Donde menos se equivoc√≥ el modelo: {le.classes_[least_missed_class]} (errores: {class_errors[least_missed_class]})\")\n",
    "\n",
    "# Calcular la importancia de los errores: se puede evaluar el n√∫mero de errores por clase en funci√≥n del total de instancias\n",
    "total_instances = cm.sum()\n",
    "error_percentage_by_class = (class_errors / total_instances) * 100\n",
    "\n",
    "print(\"\\nüîπ Importancia de los errores por clase (en porcentaje):\")\n",
    "for i, error_percent in enumerate(error_percentage_by_class):\n",
    "    print(f\"Clase '{le.classes_[i]}': {error_percent:.2f}% de los errores\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verificar si est√° sobreajustado y modelo de validaci√≥n cruzada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisi√≥n en entrenamiento: 0.7466\n",
      "Precisi√≥n en prueba: 0.7637\n",
      "Precisi√≥n con validaci√≥n cruzada (media de 5 folds): 0.7397\n",
      "Matriz de confusi√≥n:\n",
      " [[ 82   3   9]\n",
      " [  0 106   4]\n",
      " [ 24  29  35]]\n",
      "Reporte de clasificaci√≥n:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        alto       0.77      0.87      0.82        94\n",
      "        bajo       0.77      0.96      0.85       110\n",
      "       medio       0.73      0.40      0.51        88\n",
      "\n",
      "    accuracy                           0.76       292\n",
      "   macro avg       0.76      0.74      0.73       292\n",
      "weighted avg       0.76      0.76      0.74       292\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Cargar los datos\n",
    "data = pd.read_csv('train.csv')\n",
    "\n",
    "# Convertir la variable objetivo en categor√≠as\n",
    "num_bins = 3  # N√∫mero de categor√≠as\n",
    "labels = ['bajo', 'medio', 'alto']\n",
    "data['SalePrice_cat'] = pd.qcut(data['SalePrice'], q=num_bins, labels=labels)\n",
    "\n",
    "# Seleccionar caracter√≠sticas y variable objetivo\n",
    "X = data.drop(['SalePrice', 'SalePrice_cat'], axis=1)\n",
    "y = data['SalePrice_cat']\n",
    "\n",
    "# Convertir variables categ√≥ricas en num√©ricas\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# Manejo de valores faltantes\n",
    "X.fillna(X.mean(), inplace=True)  # Rellenar valores num√©ricos con la media\n",
    "\n",
    "# Dividir en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Entrenar el modelo Naive Bayes\n",
    "nb_model = GaussianNB()\n",
    "nb_model.fit(X_train, y_train)\n",
    "\n",
    "# Precisi√≥n en el conjunto de entrenamiento\n",
    "y_train_pred = nb_model.predict(X_train)\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "\n",
    "# Realizar predicciones en el conjunto de prueba\n",
    "y_pred = nb_model.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Validaci√≥n cruzada\n",
    "cv_scores = cross_val_score(nb_model, X, y, cv=5)\n",
    "cv_mean = np.mean(cv_scores)\n",
    "\n",
    "# Evaluaci√≥n del modelo\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f'Precisi√≥n en entrenamiento: {train_accuracy:.4f}')\n",
    "print(f'Precisi√≥n en prueba: {test_accuracy:.4f}')\n",
    "print(f'Precisi√≥n con validaci√≥n cruzada (media de 5 folds): {cv_mean:.4f}')\n",
    "print('Matriz de confusi√≥n:\\n', conf_matrix)\n",
    "print('Reporte de clasificaci√≥n:\\n', class_report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Informe\n",
    "\n",
    "### An√°lisis del modelo\n",
    "* **Precisi√≥n Global**: 76.37% de precisi√≥n significa que el modelo claasific√≥ correctamente alrededor del 76% de los valores conjuntos de prueba. Para un modelo de Naive Bayes, es un resultado aceptable.\n",
    "* **Matriz de confusi√≥n**: \n",
    "    * Clase **alto**: 82 predicciones correctas, 12 incorrectas\n",
    "    * Clase **media**: Buena precisi√≥n y recall alto, lo que significa que casi todos los casos reales de \"bajo\" fueron clasificados correctamente\n",
    "    * Clase **medio**: Tiene la peor rendimiento con recall de 40% indicando que el modelo tiene problemas para identificar la categor√≠a.\n",
    "### Comparaci√≥n de los modelos\n",
    "* **Modelo Regresi√≥n Lineal**: Tiene un 79.9% de precisi√≥n, tiene los coeficientes m√°s estables.\n",
    "* **Modelo √Årbol de Regresi√≥n**: Precisi√≥n de 79.58%, este siendo de produndidad 10.\n",
    "* **Modelo Naive Bayes**: Precisi√≥n de 76.37%, valor aceptable\n",
    "\n",
    "En general el modelo de regresi√≥n lineal ajustado que se hizo con anterioridad sigue siendo el mejor modelo para la predicci√≥n.\n",
    "\n",
    "### An√°lisis Sobreajustamiento y Modelo de validaci√≥n cruzada\n",
    "* La precisi√≥n del entrenamiedo fue de 74.66% y la precisi√≥n en prueba de 76.37%, como no es una diferencia signidicativa entonces el modelo **no** esta sobreajustado.\n",
    "* La precisi√≥n de la validaci√≥n cruzada fue de 73.97%, es ligeramente menor que la precisi√≥n en prueba pero en general indica que el modelo es estable y generaliza bien a distintos conjuntos de datos.\n",
    "\n",
    "### Conclusiones\n",
    "* El modelo Naive Bayes predice con buena presici√≥n las categorias \"alto\" y \"bajo\"\n",
    "* El modelo no est√° sobreajustado\n",
    "* No hay una gran diferencia entre entrenamiento, prueba y validaci√≥n cruzada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
